{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tweepy==3.10.0\n",
    "\n",
    "import json\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('src/credential.json','r') as f:\n",
    "    credential = json.load(f)\n",
    "\n",
    "CONSUMER_KEY = credential['twitter_api_key']\n",
    "CONSUMER_SECRET = credential['twitter_api_secret_key']\n",
    "ACCESS_TOKEN = credential['twitter_access_token']\n",
    "ACCESS_TOKEN_SECRET = credential['twitter_access_token_secret']\n",
    "bearer_token = credential['bearer_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleStreamListener(tweepy.StreamListener):\n",
    "    \n",
    "    def on_status(self, status):\n",
    "        tweet = json.dumps({\n",
    "            'id': status.id, \n",
    "            'name': status.user.name, \n",
    "            'user_location': status.user.location,\n",
    "            'text': status.text, \n",
    "            'fav': status.favorite_count, \n",
    "            'tweet_date': status.created_at.strftime(\"%Y-%m-%d %H:%M:%S\"), \n",
    "            'tweet_location': status.place.full_name if status.place else None}, \n",
    "            default=str)\n",
    "\n",
    "            \n",
    "    def on_error(self, status_code):\n",
    "        print(status_code)\n",
    "        if status_code == 420:\n",
    "            return False\n",
    "\n",
    "stream_listener = SimpleStreamListener()\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "twitterStream = tweepy.Stream(auth, stream_listener)\n",
    "twitterStream.filter(track=['Starbucks'], languages=['en'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install confluent_kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### kafka\n",
    "# ref: https://docs.confluent.io/platform/current/clients/confluent-kafka-python/html\n",
    "import asyncio\n",
    "\n",
    "from confluent_kafka import Consumer, Producer\n",
    "from confluent_kafka.admin import AdminClient, NewTopic\n",
    "\n",
    "BROKER_URL = \"PLAINTEXT://localhost:9092\"\n",
    "TOPIC_NAME = \"test\"\n",
    "\n",
    "### twitter\n",
    "import tweepy\n",
    "from tweepy.auth import OAuthHandler\n",
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "import json\n",
    "import logging \n",
    "\n",
    "\n",
    "### logging \n",
    "FORMAT = \"%(asctime)s | %(name)s - %(levelname)s - %(message)s\"\n",
    "LOG_FILEPATH = \"/workspace/twitter_topic_analysis_dashboard/logs/testing.log\"\n",
    "logging.basicConfig(\n",
    "    filename=LOG_FILEPATH,\n",
    "    level=logging.INFO,\n",
    "    filemode='w',\n",
    "    format=FORMAT)\n",
    "\n",
    "### Authenticate to Twitter\n",
    "with open('src/credential.json','r') as f:\n",
    "    credential = json.load(f)\n",
    "\n",
    "CONSUMER_KEY = credential['twitter_api_key']\n",
    "CONSUMER_SECRET = credential['twitter_api_secret_key']\n",
    "ACCESS_TOKEN = credential['twitter_access_token']\n",
    "ACCESS_TOKEN_SECRET = credential['twitter_access_token_secret']\n",
    "BEARER_TOKEN = credential['bearer_token']\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Purchase:\n",
    "    username: str = field(default_factory=faker.user_name)\n",
    "    currency: str = field(default_factory=faker.currency_code)\n",
    "    amount: int = field(default_factory=lambda: random.randint(100, 200000))\n",
    "\n",
    "    def serialize(self):\n",
    "        \"\"\"Serializes the object in JSON string format\"\"\"\n",
    "        # TODO: Serializer the Purchase object\n",
    "        #       See: https://docs.python.org/3/library/json.html#json.dumps\n",
    "        return json.dumps(\n",
    "                {\n",
    "                        \"username\": self.username,\n",
    "                        \"currency\": self.currency,\n",
    "                        \"amount\"  : self.amount,\n",
    "                }\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SimpleStreamListener(tweepy.StreamListener):\n",
    "    \"\"\"\n",
    "    Streaming the recent tweets related to the query to Azure Datalake\n",
    "    \"\"\"\n",
    "\n",
    "    def on_status(self, status):\n",
    "        tweet = json.dumps({\n",
    "            'id': status.id, \n",
    "            'name': status.user.name, \n",
    "            'user_location':status.user.location, \n",
    "            'text': status.text, \n",
    "            'fav': status.favorite_count, \n",
    "            'tweet_date': status.created_at.strftime(\"%Y-%m-%d %H:%M:%S\"), \n",
    "            'tweet_location': status.place.full_name if status.place else None\n",
    "        }, default=str)  \n",
    "        print(tweet)\n",
    "        return tweet\n",
    "    \n",
    "\n",
    "def streaming_tweets():\n",
    "    stream_listener = SimpleStreamListener()\n",
    "    auth = tweepy.OAuthHandler(consumer_key=CONSUMER_KEY, consumer_secret = CONSUMER_SECRET)\n",
    "    auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "    twitterStream = tweepy.Stream(auth, stream_listener)\n",
    "    twitterStream.filter(track=['starbucks'], languages=['en'])\n",
    "\n",
    "\n",
    "\n",
    "async def produce(topic_name):\n",
    "    \"\"\"\n",
    "    Produces data into the Kafka Topic\n",
    "    :param topic_name:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    p = Producer({\"bootstrap.servers\": BROKER_URL})\n",
    "\n",
    "    try:\n",
    "        # produce a message to the topic \n",
    "        p.produce(topic_name, Purchase().serialize())\n",
    "        p.flush()\n",
    "        await asyncio.sleep(0.01)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False\n",
    "\n",
    "\n",
    "async def consumer(topic_name):\n",
    "    \"\"\"\n",
    "    Consumes data from the Kafka topic\n",
    "    :param topic_name:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Configure the consumer with 'bootstrap.servers' and 'group.id' (not applicable in this case)\n",
    "    c = Consumer({\"bootstrap.servers\": BROKER_URL, \"group.id\": \"test\"})\n",
    "\n",
    "    # Subscribe to the topic\n",
    "    c.subscribe([topic_name])\n",
    "\n",
    "    message = c.consume(timeout=0.01)\n",
    "\n",
    "    # Handle the message\n",
    "    if message is None:\n",
    "        await asyncio.sleep(0.01)\n",
    "        logging.ERROR(\"No message is recevied by consumer\")    \n",
    "\n",
    "async def produce_consume():\n",
    "    \"\"\"\n",
    "    Runs the Producer and Consumer task\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    t1 = asyncio.create_task(produce(TOPIC_NAME))\n",
    "    t2 = asyncio.create_task(consumer(TOPIC_NAME))\n",
    "    await t1\n",
    "    await t2\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    runs the exercise\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Configure the AdminClient with 'bootstrap.servers' \n",
    "    client = AdminClient({\"bootstrap.servers\": BROKER_URL})\n",
    "\n",
    "    # Create a NewTopic object\n",
    "    topic = NewTopic(TOPIC_NAME, num_partitions = 1, replication_factor = 1)\n",
    "\n",
    "    # Using 'client', create the topic\n",
    "    client.create_topics([topic])\n",
    "\n",
    "    try:\n",
    "        asyncio.run(produce_consume())\n",
    "    except KeyboardInterrupt as e:\n",
    "        logging.INFO('Shutting Down')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "streaming_tweets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BROKER_URL = \"localhost:9092\"\n",
    "TOPIC_NAME = \"testing2\"\n",
    "\n",
    "### twitter\n",
    "import tweepy\n",
    "from tweepy.auth import OAuthHandler\n",
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "import json\n",
    "import logging \n",
    "\n",
    "\n",
    "### logging \n",
    "FORMAT = \"%(asctime)s | %(name)s - %(levelname)s - %(message)s\"\n",
    "LOG_FILEPATH = \"/workspace/twitter_topic_analysis_dashboard/logs/testing.log\"\n",
    "logging.basicConfig(\n",
    "    filename=LOG_FILEPATH,\n",
    "    level=logging.INFO,\n",
    "    filemode='w',\n",
    "    format=FORMAT)\n",
    "\n",
    "### Authenticate to Twitter\n",
    "with open('src/credential.json','r') as f:\n",
    "    credential = json.load(f)\n",
    "\n",
    "CONSUMER_KEY = credential['twitter_api_key']\n",
    "CONSUMER_SECRET = credential['twitter_api_secret_key']\n",
    "ACCESS_TOKEN = credential['twitter_access_token']\n",
    "ACCESS_TOKEN_SECRET = credential['twitter_access_token_secret']\n",
    "BEARER_TOKEN = credential['bearer_token']\n",
    "\n",
    "class SimpleStreamListener(tweepy.StreamListener):\n",
    "    \"\"\"\n",
    "    Streaming the recent tweets related to the query to Azure Datalake\n",
    "    \"\"\"\n",
    "\n",
    "    def on_status(self, status):\n",
    "        tweet = json.dumps({\n",
    "            'id': status.id, \n",
    "            'name': status.user.name, \n",
    "            'user_location':status.user.location, \n",
    "            'text': status.text, \n",
    "            'fav': status.favorite_count, \n",
    "            'tweet_date': status.created_at.strftime(\"%Y-%m-%d %H:%M:%S\"), \n",
    "            'tweet_location': status.place.full_name if status.place else None\n",
    "        }, default=str)  \n",
    "\n",
    "        producer.send(topic_name, str.encode(status))\n",
    "        return True\n",
    "    \n",
    "\n",
    "async def produce_streaming_tweets():\n",
    "    \"\"\"\n",
    "    Produces data into the Kafka Topic\n",
    "    :param topic_name:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    stream_listener = SimpleStreamListener()\n",
    "    auth = tweepy.OAuthHandler(consumer_key=CONSUMER_KEY, consumer_secret = CONSUMER_SECRET)\n",
    "    auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "    twitterStream = tweepy.Stream(auth, stream_listener)\n",
    "    twitterStream.filter(track=['starbucks'], languages=['en'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web Scrapping"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
